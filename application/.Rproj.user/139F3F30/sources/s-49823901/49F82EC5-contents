#' @title Get performance measures for network inference
#' @description Computes the sensitivity, specificity, f1score, tdr, and tndr
#'   to measure the accuracy of an inferred network on the true network.
#' @param pred a matrix indicating the predicted connections
#'   between the genes. Can be adjacency matrix or sparse association matrix 
#'   (i.e. with non-significant associations removed); all non-zero entries are
#'   changed to 1. 
#' @param true a network object or an adjacency matrix indicating the 
#' true underlying connections in the graph.
#' @return A list containing sensitivity, specificity, f1_score, tdr (true 
#' discovery rate), and tndr (true non-discovery rate). If the predicted network
#' is empty, then tdr is set to NA. Similarly, if the predicted network is completely
#' connected, tndr is set to NA.
get_network_inference_performance <- function(pred, true) {
  if(class(true) == "network") {
    true <- get_adj_matrix_from_network(true)
  } else if((!is.matrix(true))) {
    stop("true should be a network or matrix.")
  }
  if(!is.matrix(pred)) {
    stop("pred is not a matrix.")
  }
  if(dim(pred)[1] != dim(pred)[2]) {
    stop("pred is not a square matrix.")
  }
  if(dim(true)[1] != dim(true)[2]) {
    stop("true is not a square matrix.")
  }
  if(dim(pred)[1] != dim(true)[1]) {
    stop("true and pred are not of equal dimension.")
  }
  if(!isSymmetric(unname(true))) {
    stop("true is not symmetric.")
  }
  if(!isSymmetric(unname(pred))) {
    stop("pred is not symmetric.")
  }
  
  # Change any non-zero entries in pred to 1. 
  pred[pred != 0] <- 1
  
  # Take values in lower triangle.
  true <- true[lower.tri(true)]
  pred <- pred[lower.tri(pred)]
  
  # Setup:
  #           pred
  #           1  0
  #           ----
  # true  1 | A  B
  #       0 | C  D
  #
  # sensitivity = A / (A + B)
  # specificity = D / (C + D)
  # f1-score = harmonic mean of sensitivity and specificity
  # tdr = A / (A + C)
  # tndr = D / (B + D)
  
  pred_1 <- pred == 1 
  true_1 <- true == 1
  
  A <- sum(pred_1 & true_1)
  B <- sum(!pred_1 & true_1)
  C <- sum(pred_1 & !true_1)
  D <- sum(!pred_1 & !true_1)
  
  sensitivity <- A / (A + B)
  specificity <- D / (C + D)
  f1_score <-  2 / (1 / sensitivity + 1 / specificity)
  tdr <- ifelse((A + C) == 0, NA, A / (A + C))
  tndr <- ifelse((B + D) == 0, NA, D / (B + D))
  
  return(list(sensitivity = sensitivity, specificity = specificity,
              f1_score = f1_score, tdr = tdr, tndr = tndr))
}

#Performs tests to determine if get_performance_measures() is working properly.
test_network_measures <- function() {
  PASS <- TRUE
  assoc_true <- matrix(c(0, 1, 1, 0, 0,
                         1, 0, 1, 0, 1,
                         1, 1, 0, 0, 0,
                         0, 0, 0, 0, 1,
                         0, 1, 0, 1, 0), 5, 5)
  
  assoc_test1 <- assoc_true
  measures_test1 <- unlist(get_network_inference_performance(assoc_test1, assoc_true))
  if(any(measures_test1 != rep(1, 5))) {
    warning("performance measures did not pass test 1.")
    PASS <- FALSE
  }
  
  assoc_test2 <- !assoc_true
  measures_test2 <- unlist(get_network_inference_performance(assoc_test2, assoc_true))
  if(any(measures_test2 != rep(0, 5))) {
    warning("performance measures did not pass test 2.")
    PASS <- FALSE
  }
  
  assoc_test3 <- matrix(c(0, 1, 0, 0, 0,
                          1, 0, 0, 0, 1,
                          0, 0, 0, 1, 1,
                          0, 0, 1, 0, 1,
                          0, 1, 1, 1, 0), 5, 5)
  measures_test3 <- unlist(get_network_inference_performance(assoc_test3, assoc_true))
  if(any(measures_test3 != rep(3/5, 5))) {
    warning("performance measures did not pass test 3.")
    PASS <- FALSE
  }
  
  assoc_test4 <- matrix(c(0, 1, 0, 0, 0,
                          1, 0, 0, 0, 1,
                          0, 0, 0, 1, 1,
                          0, 0, 1, 0, 1,
                          0, 1, 1, 1, 0), 5, 5) * rnorm(25, 0, 1)
  assoc_test4 <- t(assoc_test4) + assoc_test4
  measures_test4 <- unlist(get_network_inference_performance(assoc_test4, assoc_true))
  if(any(measures_test4 != rep(3/5, 5))) {
    warning("performance measures did not pass test 4.")
    PASS <- FALSE
  }
  
  
  if(PASS) {
    print("All tests were passed.")
  }
}


diff_connectivity_performance <- function(diff_score, diff_true) {
  if(is.list(diff_score)) {
    for(score in diff_score) {
      
    }
  }
}


#' Compute ROC curve 
#' 
#' @param true A vector of true labels.
#' @param pred A vector of predicted 
#' @return 
get_roc <- function(true, pred) {
  if(is.factor(true) & length(levels(true)) != 2)
    strop("true should only contain two factor levels.")
  if(!all(true %in% c(0, 1)))
    stop("true is not a factor nor is a vector of 0's and 1's.")
  
  if(is.matrix(pred)) pred <- pred[lower.tri(pred)]
  if(is.matrix(true)) true <- true[lower.tri(true)]
  
  ranked <- order(abs(pred), decreasing = TRUE)
  pred <- pred[ranked]
  true <- true[ranked]
  
  sens <- c(0, cumsum(true) / sum(true))
  spec <- c(1, 1 - cumsum(!true) / sum(!true))
  tdr <- c(0, cumsum(true) / (1:length(true)))
  tndr <- c(rev(cumsum(!true)) / (length(true):1), 0)
  df <- data.frame(sens = sens, 
                   spec = spec, 
                   tdr = tdr,
                   tndr = tndr)
  class(df) <- "ROC"
  return(df)
}

print.ROC <- function(roc, digits = 4, ...) {
  n <- length(roc$sens) - 1 
  auc <- get_auc(roc)
  max_f1_score <- 2 * prod(c(roc$tdr[n + 1], roc$sens[n + 1])) / 
    sum(c(roc$tdr[n + 1], roc$sens[n + 1]))
  tdr_range <- range(roc$tdr[-1])
  tndr_range <- range(roc$tndr[1:n])
  
  cat("Sample size:", n,
      "\nTrue discovery rate: from", round(tdr_range[1], digits), 
      "to", round(tdr_range[2], digits), 
      "\nTrue non-discovery rate: from", round(tndr_range[1], digits), 
      "to", round(tndr_range[2], digits), 
      "\nArea under Curve:", round(auc, digits),
      "\nMaximum F1 Score:", round(max_f1_score, digits), "\n")
}

plot_roc <- function(roc, title = "ROC curve", ...) {
  if(class(roc) != "ROC")
    stop(paste("not applicable for an object of class", class(roc)))
  
  auc <- get_auc(x = (1 - roc$spec), y = roc$sens)
  g <- data.frame(spec = roc$spec, sens = roc$sens) %>%
    as.data.frame() %>%
    ggplot(aes(x = 1 - spec, y = sens)) +
    geom_line() +
    geom_abline(intercept = 0, slope = 1, linetype = 3) +
    theme_bw() +
    lims(y = c(0, 1),
         x = c(0, 1)) +
    labs(x = "1 - specificity", 
         y = "sensitivity",
         title = title) +
    geom_text(x = 0.8, y = 0.1, size = 6,
              aes(label = paste("AUC =", round(auc, 3))))
  plot(g)
  return(g)
}


plot_pr <- function(roc, title = "Precision-Recall curve", ...) {
  if(class(roc) != "ROC")
    stop(paste("not applicable for an object of class", class(roc)))
  
  auc <- get_auc(x = roc$sens, y = roc$tdr)
  
  g <- data.frame(sens = roc$sens, tdr = roc$tdr) %>%
    ggplot(aes(sens, tdr)) +
    geom_line() +
    geom_abline(intercept = 0, slope = 1, linetype = 3) +
    theme_bw() +
    lims(y = c(0, 1),
         x = c(0, 1)) +
    labs(x = "Recall", 
         y = "Precision",
         title = title) +
    geom_text(x = 0.8, y = 0.1, size = 6,
              aes(label = paste("AUC =", round(auc, 3))))
  plot(g)
  return(g)
}

plot.ROC <- plot_roc

#' Get area under the curve
#' 
#' Can be applied to an roc object to obtain AUROC, or the user may specify
#' values for x and y.
#' @param roc An object of class roc.
#' @param x An optional vector of x-coordinates for the curve.
#' @param y An optional vector of y-coordinates for the curve.
#' @return The estimated area under the curve.
#' @example get_auc(get_roc(rbinom(100, 1, 0.5), runif(100, 0, 1)))
get_auc <- function(roc = NULL, x = NULL, y = NULL) {
  if(!is.null(roc)) {
    if(class(roc) != "ROC")
      stop(paste("not applicable for an object of class", class(roc)))
    if(is.null(x))
      x <- 1 - roc$spec
    if(is.null(y))
      y <- roc$sens
  }
  
  if(length(x) != length(y)) 
    stop("x and y have differening lengths.")
  
  y <- y[-1]
  n <- length(x)
  auc <- sum(y * (x[-1] - x[-n]))
  return(auc)
}
